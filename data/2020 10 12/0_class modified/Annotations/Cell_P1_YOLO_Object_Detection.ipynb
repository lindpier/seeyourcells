{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of WYSIWYG Object_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHI6iEfwVUzX",
        "colab_type": "text"
      },
      "source": [
        "# 물체 탐지(Object detection) : YOLO3로 CELL 탐지와 분류\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKsqInIkeXIU",
        "colab_type": "text"
      },
      "source": [
        "## YOLOv3 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoJoYY7MctLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwiIw0W-UbPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y keras\n",
        "!pip install keras==2.2.4\n",
        "\n",
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekRsfKJCec-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 프로젝트 다운로드\n",
        "%cd /content\n",
        "!rm -rf darknet\n",
        "!git clone https://github.com/pjreddie/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQr78KR8ep2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 빌드\n",
        "%cd /content/darknet\n",
        "!make\n",
        "\n",
        "# 빌드된 실행파일 확인\n",
        "!ls -al darknet\n",
        "# 빌드 확인\n",
        "!./darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2IYZ85cg6H7",
        "colab_type": "text"
      },
      "source": [
        "## YOLO 학습된 모델 파일 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkclgVawg9AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/darknet\n",
        "!wget wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY9e-auCG63F",
        "colab_type": "text"
      },
      "source": [
        "## Keras 변환 코드 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNgjI9jG433J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 다운로드\n",
        "%cd /content\n",
        "!rm -rf keras-yolo3\n",
        "\n",
        "!git clone https://github.com/qqwweee/keras-yolo3\n",
        "  \n",
        "# 다운로드된 디렉토리로 이동\n",
        "%cd keras-yolo3\n",
        "\n",
        "# 내용 확인\n",
        "!pwd\n",
        "!ls -al  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmn19zun6grm",
        "colab_type": "text"
      },
      "source": [
        "## YOLO3 모델 파일 카피\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FgHeVfQ6geU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/keras-yolo3\n",
        "!cp /content/darknet/yolov3.weights ./\n",
        "!ls -al yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PlyEQg7Z__4",
        "colab_type": "text"
      },
      "source": [
        "## 모델 파일 변환\n",
        "\n",
        "YOLO3 자체는 C/C++로 구현된 DarkNet 프레임웤으로 구현되어 있다. \n",
        "\n",
        "공개된 모델은 DarkNet의 포멧이다. 이를 Keras에서 사용할 수 있는 h5 포멧으로 변환한다.\n",
        "\n",
        "\n",
        "- convert.py : 변환 실행 파일\n",
        "\n",
        "- yolov3.cfg : Darknet에서 사용하는 모델 구조 정의 파일\n",
        "\n",
        "- yolov3.weight : Darknet으로 학습된 모델 파일\n",
        "\n",
        "\n",
        "실행 결과로 다음의 h5 파일로 변환된다.\n",
        " \n",
        "- model/yolov3.h5 : 변환된 모델 파일\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dftAKD1gHio7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#yolov3.cfg 파일 내용 확인\n",
        "!head -40 yolov3.cfg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxOn_JdqtUuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 실행하기전 기존것이 있다면 삭제\n",
        "\n",
        "!rm -rf yolov3-tiny.h5\n",
        "\n",
        "# 실행 \n",
        "%run convert.py yolov3-tiny.cfg yolov3.weights yolov3-tiny.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvOIOGIG8Xja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 실행하기전 기존것이 있다면 삭제\n",
        "!rm -rf yolov3.h5\n",
        "\n",
        "# 실행 \n",
        "%run convert.py yolov3.cfg yolov3.weights yolov3.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se-EGy95D1ee",
        "colab_type": "text"
      },
      "source": [
        "# Cell_P1 데이터 적용\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCbkGjxLq3KM",
        "colab_type": "text"
      },
      "source": [
        "## Cell_P1 데이터 업로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HG3Gbjrq5ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/keras-yolo3\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# 파일이름 cell_P1.zip\n",
        "uploaded = files.upload()\n",
        "!ls -al "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz513uFOpJDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#zip 압축 파일 풀기\n",
        "\n",
        "!mkdir cell_P1\n",
        "!unzip cell_P1.zip -d ./cell_P1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jW5ikEvajcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 압출 풀린 파일들 확인\n",
        "!ls -al cell_P1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjKv_cCGbJeU",
        "colab_type": "text"
      },
      "source": [
        "## VOC 포멧의 레이블링 데이터를  darknet 포멧으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTKOwOAmTJhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy and modified from voc_annotation.py\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import getcwd\n",
        "import glob\n",
        "\n",
        "\n",
        "def convert_voc_2_darknet(data_folder_name, converted_file_name):\n",
        "  \n",
        "  def load_classes():\n",
        "      with open('%s/classes.txt'%(data_folder_name)) as f:\n",
        "          classes = f.read().splitlines()\n",
        "\n",
        "      return classes\n",
        "\n",
        "  def convert_annotation(image_id, converted_file):\n",
        "      tree=ET.parse('%s/Annotations/%s.xml'%(data_folder_name, image_id))\n",
        "      root = tree.getroot()\n",
        "\n",
        "      for obj in root.iter('object'):\n",
        "          difficult = obj.find('difficult').text\n",
        "          cls = obj.find('name').text\n",
        "          if cls not in classes or int(difficult)==1:\n",
        "              continue\n",
        "          cls_id = classes.index(cls)\n",
        "          xmlbox = obj.find('bndbox')\n",
        "          b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
        "          converted_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
        "\n",
        "  # classes = [' '] need to be updated\n",
        "  classes = load_classes()\n",
        "\n",
        "  # image_ids = ['101', '102', ... '305']\n",
        "  image_ids = [ f.replace(\".xml\", \"\").replace(\"%s/Annotations/\"%(data_folder_name), \"\") for f in glob.glob('%s/Annotations/*.xml'%(DATA_FOLDER_NAME))]\n",
        "\n",
        "  wd = getcwd()\n",
        "\n",
        "\n",
        "  converted_file = open(converted_file_name, 'w')\n",
        "  for image_id in image_ids:\n",
        "      converted_file.write('%s/JPEGImages/%s.jpg'%(data_folder_name, image_id))\n",
        "      convert_annotation(image_id, converted_file)\n",
        "      converted_file.write('\\n')\n",
        "  converted_file.close()\n",
        "\n",
        "\n",
        "DATA_FOLDER_NAME = \"cell_P1\"\n",
        "CONVERTED_FILE_NAME = \"train_all.txt\"\n",
        "\n",
        "convert_voc_2_darknet(DATA_FOLDER_NAME, CONVERTED_FILE_NAME)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peYhkVY5b2ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_all.txt 파일 확인\n",
        "!ls -al train_all.txt\n",
        "!head -10 train_all.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Y8NPMhIu37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy and modified from train.py\n",
        "\n",
        "\"\"\"\n",
        "Retrain the YOLO model for your own dataset.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "#    annotation_path = 'train.txt'\n",
        "    annotation_path = 'train_all.txt' # Modified\n",
        "    log_dir = 'logs/000/'\n",
        "#    classes_path = 'model_data/voc_classes.txt' # Modified    \n",
        "    classes_path = 'cell_P1/classes.txt'\n",
        "    anchors_path = 'model_data/yolo_anchors.txt'\n",
        "    class_names = get_classes(classes_path)\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "\n",
        "    input_shape = (416, 416) # multiple of 32, hw\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "#            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "            freeze_body=2, weights_path='yolov3_tiny.h5') # Modified\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes,\n",
        "#            freeze_body=2, weights_path='model_data/yolo_weights.h5')\n",
        "            freeze_body=2, weights_path='yolov3.h5') # Modified\n",
        "\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.1\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        # batch_size = 32 modified\n",
        "        batch_size = 16\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=50,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])\n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
        "\n",
        "    # Unfreeze and continue training, to fine-tune.\n",
        "    # Train longer if the result is not good.\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        # batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
        "        batch_size = 16 # note that more GPU memory is required after unfreezing the body\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=100,\n",
        "            initial_epoch=50,\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
        "\n",
        "    # Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "  #          weights_path='model_data/yolo_weights.h5'):\n",
        "              weights_path='yolov3.h5'): # Modified\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "           # weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "              weights_path='yolov3_tiny.h5'): # modified\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n",
        "_main()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTuWqNUst9pu",
        "colab_type": "text"
      },
      "source": [
        "# Train된 모델로 Cell 이미지 물체 탐지 실행\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr-Q1t7jkqSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display \n",
        "from PIL import Image\n",
        "from yolo import YOLO\n",
        "\n",
        "def do_object_detection(file, model_path, class_path):\n",
        "  \n",
        "  yolo = YOLO(model_path=model_path, classes_path=class_path)\n",
        "\n",
        "  # 이미지 로딩\n",
        "  image = Image.open(file)\n",
        "\n",
        "  # 실행\n",
        "  result_image = yolo.detect_image(image)\n",
        "\n",
        "  # 실행 결과 표시\n",
        "  display(result_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8PjaJtwZhQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#로그로 기록된 모델 확인\n",
        "!ls -al logs/000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKbqwVTVhjYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지와 모델 이름을 입력해서 이미지의 물체 탐지와 분류 실행\n",
        "\n",
        "%cd \"/content/keras-yolo3\"\n",
        "\n",
        "# do_object_detection('/content/0945.jpg', 'logs/000/ep063-loss69.857-val_loss72.440.h5', 'cell_P1/classes.txt')\n",
        "do_object_detection('cell_P1/JPEGImages/0174.jpg', 'logs/000/ep063-loss69.857-val_loss72.440.h5', 'cell_P1/classes.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}